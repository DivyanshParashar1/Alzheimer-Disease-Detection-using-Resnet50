{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4229472,"sourceType":"datasetVersion","datasetId":2492800}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:38:29.796913Z","iopub.execute_input":"2025-12-18T16:38:29.797767Z","iopub.status.idle":"2025-12-18T16:39:40.880236Z","shell.execute_reply.started":"2025-12-18T16:38:29.797731Z","shell.execute_reply":"2025-12-18T16:39:40.878961Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image, UnidentifiedImageError\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Configuration\nBATCH_SIZE = 32 * 2  # Scaled for 2 GPUs\nLEARNING_RATE = 0.001\nEPOCHS = 10\nIMG_SIZE = 224\nDATA_DIR = '/kaggle/input/augmented-alzheimer-mri-dataset/AugmentedAlzheimerDataset'\n\n# Device Configuration for Multi-GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nif torch.cuda.device_count() > 1:\n    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\nelse:\n    print(\"Warning: 2 GPUs not found. Training will proceed on available hardware.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:39:54.491681Z","iopub.execute_input":"2025-12-18T16:39:54.492077Z","iopub.status.idle":"2025-12-18T16:40:01.266120Z","shell.execute_reply.started":"2025-12-18T16:39:54.492054Z","shell.execute_reply":"2025-12-18T16:40:01.265323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def safe_loader(path):\n    try:\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n    except (UnidentifiedImageError, OSError):\n        print(f\"Skipping corrupt image: {path}\")\n        # Return a black image to prevent crashing, or handle explicitly in dataset\n        return Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n\n# Define Transforms\ntransform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])\n])\n\n# Load Dataset with specific loader\nfull_dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform, loader=safe_loader)\n\n# Split into Train and Validation (80/20 split)\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\nprint(f\"Classes: {full_dataset.classes}\")\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Validation samples: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:07.356849Z","iopub.execute_input":"2025-12-18T16:40:07.357484Z","iopub.status.idle":"2025-12-18T16:40:25.185952Z","shell.execute_reply.started":"2025-12-18T16:40:07.357458Z","shell.execute_reply":"2025-12-18T16:40:25.185190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model(num_classes):\n    model = models.resnet50(pretrained=True)\n    \n    # Freeze early layers (optional, usually good for small med datasets)\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # Replace the final fully connected layer\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Sequential(\n        nn.Linear(num_ftrs, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, num_classes)\n    )\n    \n    return model\n\nmodel = get_model(len(full_dataset.classes))\n\n# Apply DataParallel if multiple GPUs are available\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\nmodel = model.to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:40.277614Z","iopub.execute_input":"2025-12-18T16:40:40.278201Z","iopub.status.idle":"2025-12-18T16:40:41.523953Z","shell.execute_reply.started":"2025-12-18T16:40:40.278180Z","shell.execute_reply":"2025-12-18T16:40:41.523346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n    train_losses, val_losses = [], []\n    train_accs, val_accs = [], []\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(\"-\" * 10)\n\n        # --- Training Phase ---\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct / total\n        train_losses.append(epoch_loss)\n        train_accs.append(epoch_acc)\n\n        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n        # --- Validation Phase ---\n        model.eval()\n        val_running_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                val_running_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n\n        val_loss = val_running_loss / len(val_loader.dataset)\n        val_acc = val_correct / val_total\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n        print()\n\n    return train_losses, train_accs, val_losses, val_accs\n\n# Start Training\nhistory = train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:40:54.531801Z","iopub.execute_input":"2025-12-18T16:40:54.532063Z","iopub.status.idle":"2025-12-18T16:54:03.089813Z","shell.execute_reply.started":"2025-12-18T16:40:54.532029Z","shell.execute_reply":"2025-12-18T16:54:03.089023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Unfreezing model for fine-tuning...\")\n\n# 1. Unfreeze all layers\nfor param in model.parameters():\n    param.requires_grad = True\n\n# 2. Lower the learning rate significantly\n# We lower it to 1e-4 or 1e-5 to avoid destroying the pre-trained weights\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\n# 3. Train for more epochs (Fine-tuning usually takes longer)\nFINE_TUNE_EPOCHS = 10\n\n# Re-use the same training function\nhistory_ft = train_model(model, train_loader, val_loader, criterion, optimizer, FINE_TUNE_EPOCHS)\n\n# 4. Combine histories for plotting\ntrain_losses += history_ft[0]\ntrain_accs += history_ft[1]\nval_losses += history_ft[2]\nval_accs += history_ft[3]\n\n# Plot updated results\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.axvline(x=EPOCHS, color='r', linestyle='--', label='Unfreeze Point') # Mark where we unfroze\nplt.legend()\nplt.title('Loss (Feature Extract + Fine Tune)')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, label='Train Acc')\nplt.plot(val_accs, label='Val Acc')\nplt.axvline(x=EPOCHS, color='r', linestyle='--', label='Unfreeze Point')\nplt.legend()\nplt.title('Accuracy (Feature Extract + Fine Tune)')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:55:23.971595Z","iopub.execute_input":"2025-12-18T16:55:23.971939Z","iopub.status.idle":"2025-12-18T17:25:55.291079Z","shell.execute_reply.started":"2025-12-18T16:55:23.971917Z","shell.execute_reply":"2025-12-18T17:25:55.290430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting results\ntrain_losses, train_accs, val_losses, val_accs = history\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.title('Loss per Epoch')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, label='Train Acc')\nplt.plot(val_accs, label='Val Acc')\nplt.title('Accuracy per Epoch')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T16:54:13.911746Z","iopub.execute_input":"2025-12-18T16:54:13.912058Z","iopub.status.idle":"2025-12-18T16:54:14.264229Z","shell.execute_reply.started":"2025-12-18T16:54:13.912026Z","shell.execute_reply":"2025-12-18T16:54:14.263311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the trained model weights\ntorch.save(model.state_dict(), 'alzheimer_resnet50.pth')\nprint(\"Model saved successfully as 'alzheimer_resnet50.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:27:01.509084Z","iopub.execute_input":"2025-12-18T17:27:01.509642Z","iopub.status.idle":"2025-12-18T17:27:01.654874Z","shell.execute_reply.started":"2025-12-18T17:27:01.509606Z","shell.execute_reply":"2025-12-18T17:27:01.653952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport pandas as pd\n\ndef evaluate_model(model, loader):\n    model.eval()\n    y_true = []\n    y_pred = []\n    \n    # Disable gradient calculation for inference\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Move to CPU to use with sklearn\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(predicted.cpu().numpy())\n            \n    return y_true, y_pred\n\n# Get predictions\nprint(\"Generating evaluation metrics...\")\ny_true, y_pred = evaluate_model(model, val_loader)\n\n# 1. Classification Report\nclass_names = full_dataset.classes\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# 2. Plot Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:27:13.842158Z","iopub.execute_input":"2025-12-18T17:27:13.842430Z","iopub.status.idle":"2025-12-18T17:27:29.734365Z","shell.execute_reply.started":"2025-12-18T17:27:13.842406Z","shell.execute_reply":"2025-12-18T17:27:29.733754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(image_path, model):\n    # Load and Preprocess\n    img = Image.open(image_path).convert('RGB')\n    img_tensor = transform(img).unsqueeze(0) # Add batch dimension\n    \n    # Predict\n    model.eval()\n    with torch.no_grad():\n        img_tensor = img_tensor.to(device)\n        outputs = model(img_tensor)\n        _, predicted = torch.max(outputs, 1)\n        \n    class_name = full_dataset.classes[predicted.item()]\n    \n    plt.imshow(img)\n    plt.title(f\"Prediction: {class_name}\")\n    plt.axis('off')\n    plt.show()\n\n# Example usage (replace with a real path from the dataset)\nsample_path = \"/kaggle/input/augmented-alzheimer-mri-dataset/OriginalDataset/ModerateDemented/28.jpg\"\npredict_image(sample_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T17:29:09.249670Z","iopub.execute_input":"2025-12-18T17:29:09.250105Z","iopub.status.idle":"2025-12-18T17:29:09.380427Z","shell.execute_reply.started":"2025-12-18T17:29:09.250082Z","shell.execute_reply":"2025-12-18T17:29:09.379852Z"}},"outputs":[],"execution_count":null}]}